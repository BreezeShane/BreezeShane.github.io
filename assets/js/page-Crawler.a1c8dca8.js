(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{791:function(s,t,a){"use strict";a.r(t);var n=a(1),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("details",{staticClass:"custom-block details"},[a("summary",[s._v("参考资料")]),s._v(" "),a("ol",[a("li",[a("a",{attrs:{href:"https://mofanpy.com/tutorials/data-manipulation/scraping/",target:"_blank",rel:"noopener noreferrer"}},[s._v("莫烦 Python 爬虫基础教程"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://www.zhihu.com/question/60280580",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python有哪些常见的、好用的爬虫框架？ - 知乎"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://www.osgeo.cn/scrapy/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Scrapy 2.5 documentation¶"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/scrapy/dirbot",target:"_blank",rel:"noopener noreferrer"}},[s._v("Scrapy Documentation Demo"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://blog.csdn.net/HuaCode/article/details/79429383",target:"_blank",rel:"noopener noreferrer"}},[s._v("Unknown command: crawl（爬虫框架Scrapy遇到的常见错误）"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://www.jb51.net/article/209743.htm",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python爬虫之教你利用Scrapy爬取图片"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://juejin.cn/post/6844904041290399751",target:"_blank",rel:"noopener noreferrer"}},[s._v("小白学 Python 爬虫（35）：爬虫框架 Scrapy 入门基础（三） Selector 选择器"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://blog.csdn.net/u014041590/article/details/85109026",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python爬虫（三）：scrapy提取数据之CSS提取器"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://blog.csdn.net/Python_sn/article/details/108827436",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python网络爬虫数据提取神器 Selector 的用法"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://www.cnblogs.com/zhanghongfeng/p/7881810.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("python网络爬虫之使用scrapy下载文件 - 一张红枫叶"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://blog.csdn.net/qq_40795214/article/details/82154464",target:"_blank",rel:"noopener noreferrer"}},[s._v("Scrapy爬虫之中文乱码问题"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://codeantenna.com/a/JlowUk9g7J",target:"_blank",rel:"noopener noreferrer"}},[s._v("python下载文件进度条_python超好用爬虫下载进度条模块"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://blog.csdn.net/yangchuan0120/article/details/109843009",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python使用aiohttp和asyncio多线程下载文件"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://leimao.github.io/blog/Python-AsyncIO-Awaitable-Coroutine-Future-Task/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python AsyncIO Awaitables: Coroutine, Future, and Task"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://www.dounaite.com/article/625c7b29ae87fd3f79680cee.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("通过一个例子分析python3异步编程过程"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://icode.best/i/35828746609683",target:"_blank",rel:"noopener noreferrer"}},[s._v("【Hard Python】【第二章-异步IO】2、异步任务在事件循环中的执行-爱代码爱编程"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://www.ruanyifeng.com/blog/2014/10/event-loop.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("JavaScript 运行机制详解：再谈Event Loop"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://homholueng.github.io/2019/10/08/fluent-python-asyncio/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Chapter 18 - 使用 asyncio 包处理并发"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://bbs.huaweicloud.com/blogs/109055",target:"_blank",rel:"noopener noreferrer"}},[s._v("一份详细的asyncio入门教程"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://huoyingwhw.com/pythonGuide/python%E8%BF%9B%E9%98%B6/asyncio3/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python进阶-面向对象-网编并发 » 13 asyncio并发编程进阶"),a("OutboundLink")],1)])])]),s._v(" "),a("h2",{attrs:{id:"前言"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[s._v("#")]),s._v(" 前言")]),s._v(" "),a("p",[s._v("入门学习网络爬虫的阶段主要参考的是"),a("a",{attrs:{href:"https://mofanpy.com/tutorials/data-manipulation/scraping/",target:"_blank",rel:"noopener noreferrer"}},[s._v("莫烦 Python"),a("OutboundLink")],1),s._v("的爬虫基础教程，按照了他的学习路线去学，因为这个教程实在是非常通俗易懂，能让你迅速掌握网络爬虫的相关基础概念。")]),s._v(" "),a("p",[s._v("在学过网络爬虫这一版块的内容之后，我发现网络爬虫本就没有那么神秘，说到底，不过是进入某一网络站点获取源码，再利用其他技术来爬取我们需要的信息。而且，我发现，到目前这个学习阶段为止，网络爬虫只是一种具备针对性的工具，也就是说当你需要获取某种数据时，你要做的工作首先就是要在目标网络站点上“踩点”——剖析目标网站的结构，并在其中找出你希望找到的目标。然后从此设计你的爬虫程序。")]),s._v(" "),a("p",[s._v("写爬虫工具常用的包有requests、beautifulsoup4、Asyncio、Aiohttp和Selenium等，皆可通过pip3安装。另外有看见关于Scrapy爬虫库的介绍，目前还没有学。")]),s._v(" "),a("h2",{attrs:{id:"beautifulsoup"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#beautifulsoup"}},[s._v("#")]),s._v(" BeautifulSoup")]),s._v(" "),a("blockquote",[a("p",[s._v("此处参考的是"),a("a",{attrs:{href:"https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/",target:"_blank",rel:"noopener noreferrer"}},[s._v("BeautifulSoup4 官方文档"),a("OutboundLink")],1)])]),s._v(" "),a("p",[s._v("使用之前要先安装，执行"),a("code",[s._v("pip install beautifulsoup4 lxml html5lib")]),s._v("来完成安装「其中最后两个是解析器，可以选择不安装」。")]),s._v(" "),a("p",[s._v("使用BeautifulSoup时需要提前引用相关的包，并且获取目标网站的网页：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" BeautifulSoup "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" bs\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" urllib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("request "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" urlopen\n\nweb_page "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" urlopen"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"https://breezeshane.github.io/index.html"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'utf-8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("web_page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" features"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'lxml'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("而且对Python友好的是，我们获取来的一切标签，皆可按照Python字典的操作方式操作标签。「而这一点官方文档也再三强调。」")]),s._v(" "),a("p",[s._v("若希望查找所有某名字的标签时，可以使用find_all方法查找，使用样例如下：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("href "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nlinks "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("link"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" link "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" href"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("links"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("这里的href就可以获取一切标签"),a("code",[s._v("<a>")]),s._v("，而如果只是希望获取其中的链接，则可使用第二行代码来生成只含有链接的列表。")]),s._v(" "),a("p",[s._v("另外，值得注意的是，find_all方法支持正则表达式，但需要引用re包，在第一行插入"),a("code",[s._v("import re")]),s._v("。Example："),a("code",[s._v('href = soup.find_all(re.compile("^li"))')]),s._v("，这表示寻找以“li”开头的所有标签，而如果希望寻找包含“li”的标签，则需写成："),a("code",[s._v('href = soup.find_all(re.compile("li"))')])]),s._v(" "),a("p",[s._v("同时，find_all方法还支持一次性获取多个类型标签，只消用逗号隔开即可。Example："),a("code",[s._v('href = soup.find_all(["link", "script"])')])]),s._v(" "),a("p",[s._v("如果想查找指定属性以及其对应的值的话，可以使用"),a("code",[s._v('soup.find_all(\'link\', {"mode" : "dark"})')]),s._v("，这表示寻找包含"),a("code",[s._v('mode="dark"')]),s._v("的link标签。")]),s._v(" "),a("p",[s._v("还有一个比较有用的标签属性——has_attr属性，可以判断该标签是否含有指定属性，是则返回True，否则为False。")]),s._v(" "),a("p",[s._v("更多具体细节可以直接查询官方文档，本文就不作赘述。")]),s._v(" "),a("h2",{attrs:{id:"requests"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#requests"}},[s._v("#")]),s._v(" Requests")]),s._v(" "),a("blockquote",[a("p",[s._v("此处参考"),a("a",{attrs:{href:"https://cn.python-requests.org/zh_CN/latest/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Requests 官方文档"),a("OutboundLink")],1)])]),s._v(" "),a("p",[s._v("传递URL参数时，可以写如下代码「此处以模拟Bing搜索为例」：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" requests\n\nr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'https://www.bing.com/search'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" params"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"q"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"BreezeShane"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("r"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("p",[s._v("其他功能相对来说较为复杂并且信息量也挺大，但很完善，因此要经常翻看官方文档，写爬虫时如果有什么需求再来查就好了。")]),s._v(" "),a("h2",{attrs:{id:"asyncio-在学了在学了-tot"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#asyncio-在学了在学了-tot"}},[s._v("#")]),s._v(" Asyncio（在学了在学了(ToT)）")]),s._v(" "),a("blockquote",[a("p",[s._v("此处参考"),a("a",{attrs:{href:"https://docs.python.org/zh-cn/3/library/asyncio.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("Asyncio 官方文档"),a("OutboundLink")],1)])]),s._v(" "),a("p",[s._v("Asyncio是异步加载库，虽说是单线程，但在较多场合情况下优胜于多线程，而我们如果需要爬取大量数据的话，异步加载还是有必要学的。从官方文档中我们也发现，学到这就已经接触了Python并发编程技术。")]),s._v(" "),a("p",[s._v("官方给出了一个程序示例：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" asyncio\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("async")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Hello ...'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("await")]),s._v(" asyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sleep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'... World!'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Python 3.7+")]),s._v("\nasyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("main"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br")])]),a("p",[s._v("上面的Asyncio Example并不难理解，async表示后面定义的函数是异步加载的模块，await一行表示执行该函数时暂停等待1秒。实际上这个就基本给出了Asyncio的使用模板。如果你希望实现什么功能，自行添加自己的代码即可，就像Movant写的程序：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" asyncio\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("async")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("job")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("                   "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# async 形式的功能")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Start job '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("await")]),s._v(" asyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sleep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("          "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v('# 等待 "t" 秒, 期间切换其他任务')]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Job '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("' takes '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("' s'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("async")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("                       "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# async 形式的功能")]),s._v("\n    tasks "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n        loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create_task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("job"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("                                       "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建任务, 但是不执行")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("await")]),s._v(" asyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("wait"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tasks"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("               "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 执行并等待所有任务完成")]),s._v("\n\nt1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nloop "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" asyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_event_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("             "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 建立 loop")]),s._v("\nloop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run_until_complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("main"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("         "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 执行 loop")]),s._v("\nloop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                                "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 关闭 loop")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Async total time : "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" t1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("p",[s._v("写的程序蛮简单，但Asyncio实际上远不止如此。")]),s._v(" "),a("p",[s._v("更多的用法可以直接去阅读文档，本人精力有限，而且意图也不在于深入精通网络爬虫，只是希望满足自己的需求而已，就不会在此继续讨论Asyncio了。如果过后遇到了什么问题，解决之后还是会回来记录一下。")]),s._v(" "),a("h2",{attrs:{id:"使用scrapy来实战"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用scrapy来实战"}},[s._v("#")]),s._v(" 使用Scrapy来实战")]),s._v(" "),a("p",[s._v("爬虫的流行框架很多，比如Scrapy、Crawley、Portia、newspaper、Python-goose、Aiohttp、Asks、Vibora、Pyppeteer、Requestium、Arsenic、Grab、Botflow、Ruia等等，难免让人眼花缭乱，但应该注意到，各框架之间是大同小异的，区别也在于基于什么技术上实现的，因此如有特别需求才需要细细甄别，一般直接无脑选择第一个就够用。如你所见，我使用了Scrapy框架，因为我没有特殊需要。")]),s._v(" "),a("p",[s._v("因为本人是一名刀客塔狂热分子，特别喜欢Arknights里的游戏音乐，然后凭借自己的搜索能力淘到了两个宝藏网站：")]),s._v(" "),a("ol",[a("li",[a("a",{attrs:{href:"https://prts.wiki/w/%E9%9F%B3%E4%B9%90%E9%89%B4%E8%B5%8F",target:"_blank",rel:"noopener noreferrer"}},[s._v("音乐鉴赏"),a("OutboundLink")],1)]),s._v(" "),a("li",[a("a",{attrs:{href:"https://arknightsost.nbh.workers.dev/",target:"_blank",rel:"noopener noreferrer"}},[s._v("GDIndex"),a("OutboundLink")],1)])]),s._v(" "),a("blockquote",[a("p",[a("s",[s._v("虽然的确可以自己解包提取，但别人做好的成果我为什么不能拿来白嫖呢？")])])]),s._v(" "),a("h3",{attrs:{id:"prts-wiki"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#prts-wiki"}},[s._v("#")]),s._v(" PRTS Wiki")]),s._v(" "),a("p",[s._v("如你所见，这两个网站资源真的丰富，我先拿第一个网站实验~~（开刀）~~，但是这里想全要的话是要自己一个一个点开下载，总共286首也太难办了点……于是我决定使用爬虫来替我完成批量下载的操作。")]),s._v(" "),a("p",[s._v("爬虫，结合之前所学，本质上是按照网站设计方式针对性制定的爬取资源模式。于是在开工之前，我首先进行网站的结构解析工作，发现该网站的目标资源分布规律十分明显：资源都分布在table标签下的tbody内，而且每个tbody标签内的前两个tr都是对应表标题和子标题，剩下tr部分都是资源文件所在的表格，而且这部分的tr标签内每一个都有两个td标签，第一个用来显示资源名称，另一个则是目标了，令人愉快的是，这个网站没做什么资源加密与隐藏的事，而是直接暴露在audio标签中的source标签内，并且亲自确认有效链接就是其src属性中的链接。")]),s._v(" "),a("p",[s._v("基于这一分析结果，我确定好自己的需要："),a("strong",[s._v("按照table的标题创建对应的文件夹，然后在其中存放下载的音频文件，且以其对应的名字命名")]),s._v("，于是就开始针对性地写爬虫脚本了。")]),s._v(" "),a("p",[s._v("首先创建爬虫项目，在命令行中执行"),a("code",[s._v("scrapy crawl ArknightsBGMCrawler")]),s._v("，这样就会在当前位置创建一个名为"),a("code",[s._v("ArknightsBGMCrawler")]),s._v("的包，其结构为：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("ArknightsBGMCrawler\n├── __init__.py\n├── items.py\n├── middlewares.py\n├── pipelines.py\n├── settings.py\n├── spiders\n│   └── __init__.py\n└── utils.py\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" directory, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" files\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br")])]),a("p",[s._v("而现在我们要做的第一件事就是创建Item Model，定义每一个对象的属性结构，"),a("code",[s._v("items.py")]),s._v("文件内代码如下：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ArknightsbgmcrawlerItem")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# define the fields for your item here like:")]),s._v("\n    folder_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    item_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    url "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("blockquote",[a("p",[s._v("如果你感觉这非常眼熟的话，那很正常，因为Scrapy框架其实也是基于ORM技术的。")])]),s._v(" "),a("p",[s._v("然后我们要做的就是创建对应的Crawler Model，于是我们在其中的spider文件夹下创建新的文件"),a("code",[s._v("PRTSCrawler.py")]),s._v("，在其中写入Crawler类对象的定义，对应的代码如下：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" ArknightsBGMCrawler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" ArknightsbgmcrawlerItem\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" ArknightsBGMCrawler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("utils "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PRTSSpider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"PRTS"')]),s._v("\n    allowed_domains "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"prts.wiki"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'https://prts.wiki/w/%E9%9F%B3%E4%B9%90%E9%89%B4%E8%B5%8F'")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        node_sources "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('".wikitable"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        items "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" node "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" node_sources"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            folder_name_from_span "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tbody > tr:first-child big"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            folder_name_from_img "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tbody > tr:first-child > th > img::attr(alt)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            songs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tbody > tr:nth-child(n+3)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" song "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" songs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                item "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ArknightsbgmcrawlerItem"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n                item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'folder_name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" clean_folder_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("folder_name_from_img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \\\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" folder_name_from_span "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" remove_tags"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("folder_name_from_span"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n                song_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" song"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"td:nth-last-child(2)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                song_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" song"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"td:last-child > audio > source::attr(src)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'item_name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" clean_song_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("remove_tags"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("song_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'url'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" song_url\n\n                items"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" items\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br")])]),a("p",[s._v("类内name变量决定后面你在运行时要写的名字；allowed_domains变量决定爬取资源的可接受域，设置这个的目的在于避免爬取其他域的资源，避免意外的访问；start_urls变量决定爬取目标的链接。")]),s._v(" "),a("p",[s._v("继承Crawler类时要重写parse方法，参数为response，代表着对应爬取资源的对象。根据我之前提到的资源分布规律，我首先选择所有对应的目标所在的table，然后去掉最后一个项（原因是最后一个是外服的BGM，只有两个有对应资源，其它都要去另外的链接找，在这里自动化处理会非常麻烦，再加上这里面可直接获取的歌曲只有两个，就懒得折腾了，过后自己再手动下载就行了）。folder_name_from_span变量获取的是每一个分类对应的表格标题，folder_name_from_img变量获取的是每一个分类对应的图片标题，这样做的原因在于网站中的每个分类并不都有表格标题，有的是只有图片，有的是只有标题，但还好图片有对应的标题，于是在"),a("code",[s._v("item['folder_name'] = clean_folder_name(folder_name_from_img) if folder_name_from_span is None else remove_tags(folder_name_from_span)")]),s._v("这里做了一个合并处理，成功做到每个分类都有对应的合适名字。songs变量则是获取每个分类下的所有可下载的歌曲所在的tr，最后遍历songs列表，给每一个song创建一个对象，并且给对象的folder_name、item_name、url属性赋值（这些属性的名字就取决于之前在"),a("code",[s._v("items.py")]),s._v("内的定义），至此parse方法就重写完成了。")]),s._v(" "),a("p",[s._v("链接获取到了，那接下来我们要做的就是下载了。据资料，我可以使用FilesPipeline来定义下载行为，除了要重写parse方法之外，还要在"),a("code",[s._v("pipelines.py")]),s._v("中定义FilesPipeline的继承类，重写file_path方法，return预期的文件名及路径即可。")]),s._v(" "),a("p",[s._v("但作为一个"),a("s",[s._v("勇敢")]),s._v("智障的技术宅，我突然脑子一拍，想用异步算法来完成批量下载，于是就开始鲁莽起来了。我先执行"),a("code",[s._v("scrapy crawl PRTS -o data.json")]),s._v("把爬取结果导出到data.json中，再由"),a("code",[s._v("Downloader.py")]),s._v("读取文件并批量下载，于是我在"),a("code",[s._v("Downloader.py")]),s._v("中写了如下代码：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" os\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" json\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" aiohttp\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" asyncio\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" tqdm "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" tqdm\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("async")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" event_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("async")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" aiohttp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ClientSession"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("connector"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("aiohttp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("TCPConnector"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("limit"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ssl"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        tasks "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n            event_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create_task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("await")]),s._v(" job"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                    session"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                    save_dir"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("SAVE_DIR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'folder_name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                    name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'item_name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('".mp3"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                    url"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'url'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" item "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" data\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        finished"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" unfinished "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("await")]),s._v(" asyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("wait"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tasks"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        all_results "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("r"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" r "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" finished"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"文件全部下载完毕: \\n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" all_results"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("async")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("job")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" save_dir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("save_dir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mkdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("save_dir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    save_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("save_dir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("save_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("file")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("await")]),s._v(" session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        file_code "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("await")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("save_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'wb'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" save_file"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            save_file"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("file_code"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            pbar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("update"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" raise_message"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("async")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("raise_message")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" __name__ "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'__main__'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    loop "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" asyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_event_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    SAVE_DIR "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./ArknightsBGMs/'")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("SAVE_DIR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mkdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("SAVE_DIR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"data.json"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"r"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        data_json "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("load"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# formatted_data_json = json.dumps(data_json, indent=4)")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# print(formatted_data_json)")]),s._v("\n        pbar "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tqdm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("total"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data_json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" desc"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Downloading"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" initial"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" unit_scale"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" colour"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'green'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        asyncio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data_json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br"),a("span",{staticClass:"line-number"},[s._v("44")]),a("br"),a("span",{staticClass:"line-number"},[s._v("45")]),a("br"),a("span",{staticClass:"line-number"},[s._v("46")]),a("br"),a("span",{staticClass:"line-number"},[s._v("47")]),a("br"),a("span",{staticClass:"line-number"},[s._v("48")]),a("br"),a("span",{staticClass:"line-number"},[s._v("49")]),a("br"),a("span",{staticClass:"line-number"},[s._v("50")]),a("br"),a("span",{staticClass:"line-number"},[s._v("51")]),a("br"),a("span",{staticClass:"line-number"},[s._v("52")]),a("br"),a("span",{staticClass:"line-number"},[s._v("53")]),a("br"),a("span",{staticClass:"line-number"},[s._v("54")]),a("br")])]),a("p",[s._v("结合我之前所学的异步知识，我首先创建好存放目录并创建一个循环事件队列，接着从前面爬取的json文件中读取出来下载连接，为了便于用户与计算机之间的交互，我另外创建了进度条对象。这之后我定义好事务并命名为job，通过async关键字修饰使其可挂起。在确保目录存在且文件未下载过的前提下，我将读取到的文件二进制流写入到预设好的文件中，在下载完成后更新进度条。")]),s._v(" "),a("p",[s._v("接下来我定义了start函数，在其中先创建连接池，并且创建事务队列，里面的元素通过create_task方法来创建事务，最后通过asyncio.wait将队列内各元素封装成Task对象，此后就是由该协程返回生成器对象（其他情况下可能也会是协程），最后由asyncio.run来驱动循环事务队列来进行。")]),s._v(" "),a("h3",{attrs:{id:"gdindex"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gdindex"}},[s._v("#")]),s._v(" GDIndex")]),s._v(" "),a("p",[a("em",[s._v("这个网站的执行策略有些不一样，先留个坑，以后或许会填，或许会删掉（。。。）")])])])}),[],!1,null,null,null);t.default=e.exports}}]);